{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data 2.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cacba0e4dc67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data 2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data 2.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Pritam datta shuvo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)? (<ipython-input-5-0378ffca0253>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-0378ffca0253>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print 'df.shape = ',df.shape\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)?\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data 2.csv')\n",
    "print 'df.shape = ',df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)? (<ipython-input-7-2adea206d981>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-2adea206d981>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print 'df.shape = ',df.shape\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)?\n"
     ]
    }
   ],
   "source": [
    "print 'df.shape = ',df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Pritam datta shuvo'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data Mining\\Investigating-Breast-Cancer-master\\Investigating-Breast-Cancer-master\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Data Mining\\Investigating-Breast-Cancer-master\\Investigating-Breast-Cancer-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Data Mining\\\\Investigating-Breast-Cancer-master\\\\Investigating-Breast-Cancer-master'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)? (<ipython-input-12-2adea206d981>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-2adea206d981>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print 'df.shape = ',df.shape\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('df.shape = ',df.shape)?\n"
     ]
    }
   ],
   "source": [
    "print 'df.shape = ',df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape =  (569, 32)\n"
     ]
    }
   ],
   "source": [
    "print('df.shape = ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406</td>\n",
       "      <td>M</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001</td>\n",
       "      <td>M</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014</td>\n",
       "      <td>M</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8511133</td>\n",
       "      <td>M</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>851509</td>\n",
       "      <td>M</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>852552</td>\n",
       "      <td>M</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>852631</td>\n",
       "      <td>M</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>852763</td>\n",
       "      <td>M</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>852781</td>\n",
       "      <td>M</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>852973</td>\n",
       "      <td>M</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>853201</td>\n",
       "      <td>M</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>921362</td>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>921385</td>\n",
       "      <td>B</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>...</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>921386</td>\n",
       "      <td>B</td>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>...</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>921644</td>\n",
       "      <td>B</td>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>...</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>922296</td>\n",
       "      <td>B</td>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>...</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>922297</td>\n",
       "      <td>B</td>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>922576</td>\n",
       "      <td>B</td>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>922577</td>\n",
       "      <td>B</td>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>...</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>922840</td>\n",
       "      <td>B</td>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>923169</td>\n",
       "      <td>B</td>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>923465</td>\n",
       "      <td>B</td>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>...</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>923748</td>\n",
       "      <td>B</td>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>923780</td>\n",
       "      <td>B</td>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>924084</td>\n",
       "      <td>B</td>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>...</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>924342</td>\n",
       "      <td>B</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>924632</td>\n",
       "      <td>B</td>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>924934</td>\n",
       "      <td>B</td>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>924964</td>\n",
       "      <td>B</td>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>...</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>925236</td>\n",
       "      <td>B</td>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>925277</td>\n",
       "      <td>B</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>B</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>B</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>B</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>M</td>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M       17.990         10.38          122.80     1001.0   \n",
       "1      842517         M       20.570         17.77          132.90     1326.0   \n",
       "2    84300903         M       19.690         21.25          130.00     1203.0   \n",
       "3    84348301         M       11.420         20.38           77.58      386.1   \n",
       "4    84358402         M       20.290         14.34          135.10     1297.0   \n",
       "5      843786         M       12.450         15.70           82.57      477.1   \n",
       "6      844359         M       18.250         19.98          119.60     1040.0   \n",
       "7    84458202         M       13.710         20.83           90.20      577.9   \n",
       "8      844981         M       13.000         21.82           87.50      519.8   \n",
       "9    84501001         M       12.460         24.04           83.97      475.9   \n",
       "10     845636         M       16.020         23.24          102.70      797.8   \n",
       "11   84610002         M       15.780         17.89          103.60      781.0   \n",
       "12     846226         M       19.170         24.80          132.40     1123.0   \n",
       "13     846381         M       15.850         23.95          103.70      782.7   \n",
       "14   84667401         M       13.730         22.61           93.60      578.3   \n",
       "15   84799002         M       14.540         27.54           96.73      658.8   \n",
       "16     848406         M       14.680         20.13           94.74      684.5   \n",
       "17   84862001         M       16.130         20.68          108.10      798.8   \n",
       "18     849014         M       19.810         22.15          130.00     1260.0   \n",
       "19    8510426         B       13.540         14.36           87.46      566.3   \n",
       "20    8510653         B       13.080         15.71           85.63      520.0   \n",
       "21    8510824         B        9.504         12.44           60.34      273.9   \n",
       "22    8511133         M       15.340         14.26          102.50      704.4   \n",
       "23     851509         M       21.160         23.04          137.20     1404.0   \n",
       "24     852552         M       16.650         21.38          110.00      904.6   \n",
       "25     852631         M       17.140         16.40          116.00      912.7   \n",
       "26     852763         M       14.580         21.53           97.41      644.8   \n",
       "27     852781         M       18.610         20.25          122.10     1094.0   \n",
       "28     852973         M       15.300         25.27          102.40      732.4   \n",
       "29     853201         M       17.570         15.05          115.00      955.1   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "539    921362         B        7.691         25.44           48.34      170.4   \n",
       "540    921385         B       11.540         14.44           74.65      402.9   \n",
       "541    921386         B       14.470         24.99           95.81      656.4   \n",
       "542    921644         B       14.740         25.42           94.70      668.6   \n",
       "543    922296         B       13.210         28.06           84.88      538.4   \n",
       "544    922297         B       13.870         20.70           89.77      584.8   \n",
       "545    922576         B       13.620         23.23           87.19      573.2   \n",
       "546    922577         B       10.320         16.35           65.31      324.9   \n",
       "547    922840         B       10.260         16.58           65.85      320.8   \n",
       "548    923169         B        9.683         19.34           61.05      285.7   \n",
       "549    923465         B       10.820         24.21           68.89      361.6   \n",
       "550    923748         B       10.860         21.48           68.51      360.5   \n",
       "551    923780         B       11.130         22.44           71.49      378.4   \n",
       "552    924084         B       12.770         29.43           81.35      507.9   \n",
       "553    924342         B        9.333         21.94           59.01      264.0   \n",
       "554    924632         B       12.880         28.92           82.50      514.3   \n",
       "555    924934         B       10.290         27.61           65.67      321.4   \n",
       "556    924964         B       10.160         19.59           64.73      311.7   \n",
       "557    925236         B        9.423         27.88           59.26      271.3   \n",
       "558    925277         B       14.590         22.68           96.39      657.1   \n",
       "559    925291         B       11.510         23.93           74.52      403.5   \n",
       "560    925292         B       14.050         27.15           91.38      600.4   \n",
       "561    925311         B       11.200         29.37           70.67      386.0   \n",
       "562    925622         M       15.220         30.62          103.40      716.9   \n",
       "563    926125         M       20.920         25.09          143.00     1347.0   \n",
       "564    926424         M       21.560         22.39          142.00     1479.0   \n",
       "565    926682         M       20.130         28.25          131.20     1261.0   \n",
       "566    926954         M       16.600         28.08          108.30      858.1   \n",
       "567    927241         M       20.600         29.33          140.10     1265.0   \n",
       "568     92751         B        7.760         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760        0.300100             0.147100   \n",
       "1            0.08474           0.07864        0.086900             0.070170   \n",
       "2            0.10960           0.15990        0.197400             0.127900   \n",
       "3            0.14250           0.28390        0.241400             0.105200   \n",
       "4            0.10030           0.13280        0.198000             0.104300   \n",
       "5            0.12780           0.17000        0.157800             0.080890   \n",
       "6            0.09463           0.10900        0.112700             0.074000   \n",
       "7            0.11890           0.16450        0.093660             0.059850   \n",
       "8            0.12730           0.19320        0.185900             0.093530   \n",
       "9            0.11860           0.23960        0.227300             0.085430   \n",
       "10           0.08206           0.06669        0.032990             0.033230   \n",
       "11           0.09710           0.12920        0.099540             0.066060   \n",
       "12           0.09740           0.24580        0.206500             0.111800   \n",
       "13           0.08401           0.10020        0.099380             0.053640   \n",
       "14           0.11310           0.22930        0.212800             0.080250   \n",
       "15           0.11390           0.15950        0.163900             0.073640   \n",
       "16           0.09867           0.07200        0.073950             0.052590   \n",
       "17           0.11700           0.20220        0.172200             0.102800   \n",
       "18           0.09831           0.10270        0.147900             0.094980   \n",
       "19           0.09779           0.08129        0.066640             0.047810   \n",
       "20           0.10750           0.12700        0.045680             0.031100   \n",
       "21           0.10240           0.06492        0.029560             0.020760   \n",
       "22           0.10730           0.21350        0.207700             0.097560   \n",
       "23           0.09428           0.10220        0.109700             0.086320   \n",
       "24           0.11210           0.14570        0.152500             0.091700   \n",
       "25           0.11860           0.22760        0.222900             0.140100   \n",
       "26           0.10540           0.18680        0.142500             0.087830   \n",
       "27           0.09440           0.10660        0.149000             0.077310   \n",
       "28           0.10820           0.16970        0.168300             0.087510   \n",
       "29           0.09847           0.11570        0.098750             0.079530   \n",
       "..               ...               ...             ...                  ...   \n",
       "539          0.08668           0.11990        0.092520             0.013640   \n",
       "540          0.09984           0.11200        0.067370             0.025940   \n",
       "541          0.08837           0.12300        0.100900             0.038900   \n",
       "542          0.08275           0.07214        0.041050             0.030270   \n",
       "543          0.08671           0.06877        0.029870             0.032750   \n",
       "544          0.09578           0.10180        0.036880             0.023690   \n",
       "545          0.09246           0.06747        0.029740             0.024430   \n",
       "546          0.09434           0.04994        0.010120             0.005495   \n",
       "547          0.08877           0.08066        0.043580             0.024380   \n",
       "548          0.08491           0.05030        0.023370             0.009615   \n",
       "549          0.08192           0.06602        0.015480             0.008160   \n",
       "550          0.07431           0.04227        0.000000             0.000000   \n",
       "551          0.09566           0.08194        0.048240             0.022570   \n",
       "552          0.08276           0.04234        0.019970             0.014990   \n",
       "553          0.09240           0.05605        0.039960             0.012820   \n",
       "554          0.08123           0.05824        0.061950             0.023430   \n",
       "555          0.09030           0.07658        0.059990             0.027380   \n",
       "556          0.10030           0.07504        0.005025             0.011160   \n",
       "557          0.08123           0.04971        0.000000             0.000000   \n",
       "558          0.08473           0.13300        0.102900             0.037360   \n",
       "559          0.09261           0.10210        0.111200             0.041050   \n",
       "560          0.09929           0.11260        0.044620             0.043040   \n",
       "561          0.07449           0.03558        0.000000             0.000000   \n",
       "562          0.10480           0.20870        0.255000             0.094290   \n",
       "563          0.10990           0.22360        0.317400             0.147400   \n",
       "564          0.11100           0.11590        0.243900             0.138900   \n",
       "565          0.09780           0.10340        0.144000             0.097910   \n",
       "566          0.08455           0.10230        0.092510             0.053020   \n",
       "567          0.11780           0.27700        0.351400             0.152000   \n",
       "568          0.05263           0.04362        0.000000             0.000000   \n",
       "\n",
       "              ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0             ...                   25.380          17.33           184.60   \n",
       "1             ...                   24.990          23.41           158.80   \n",
       "2             ...                   23.570          25.53           152.50   \n",
       "3             ...                   14.910          26.50            98.87   \n",
       "4             ...                   22.540          16.67           152.20   \n",
       "5             ...                   15.470          23.75           103.40   \n",
       "6             ...                   22.880          27.66           153.20   \n",
       "7             ...                   17.060          28.14           110.60   \n",
       "8             ...                   15.490          30.73           106.20   \n",
       "9             ...                   15.090          40.68            97.65   \n",
       "10            ...                   19.190          33.88           123.80   \n",
       "11            ...                   20.420          27.28           136.50   \n",
       "12            ...                   20.960          29.94           151.70   \n",
       "13            ...                   16.840          27.66           112.00   \n",
       "14            ...                   15.030          32.01           108.80   \n",
       "15            ...                   17.460          37.13           124.10   \n",
       "16            ...                   19.070          30.88           123.40   \n",
       "17            ...                   20.960          31.48           136.80   \n",
       "18            ...                   27.320          30.88           186.80   \n",
       "19            ...                   15.110          19.26            99.70   \n",
       "20            ...                   14.500          20.49            96.09   \n",
       "21            ...                   10.230          15.66            65.13   \n",
       "22            ...                   18.070          19.08           125.10   \n",
       "23            ...                   29.170          35.59           188.00   \n",
       "24            ...                   26.460          31.56           177.00   \n",
       "25            ...                   22.250          21.40           152.40   \n",
       "26            ...                   17.620          33.21           122.40   \n",
       "27            ...                   21.310          27.26           139.90   \n",
       "28            ...                   20.270          36.71           149.30   \n",
       "29            ...                   20.010          19.52           134.90   \n",
       "..            ...                      ...            ...              ...   \n",
       "539           ...                    8.678          31.89            54.49   \n",
       "540           ...                   12.260          19.68            78.78   \n",
       "541           ...                   16.220          31.73           113.50   \n",
       "542           ...                   16.510          32.29           107.40   \n",
       "543           ...                   14.370          37.17            92.48   \n",
       "544           ...                   15.050          24.75            99.17   \n",
       "545           ...                   15.350          29.09            97.58   \n",
       "546           ...                   11.250          21.77            71.12   \n",
       "547           ...                   10.830          22.04            71.08   \n",
       "548           ...                   10.930          25.59            69.10   \n",
       "549           ...                   13.030          31.45            83.90   \n",
       "550           ...                   11.660          24.77            74.08   \n",
       "551           ...                   12.020          28.26            77.80   \n",
       "552           ...                   13.870          36.00            88.10   \n",
       "553           ...                    9.845          25.05            62.86   \n",
       "554           ...                   13.890          35.74            88.84   \n",
       "555           ...                   10.840          34.91            69.57   \n",
       "556           ...                   10.650          22.88            67.88   \n",
       "557           ...                   10.490          34.24            66.50   \n",
       "558           ...                   15.480          27.27           105.90   \n",
       "559           ...                   12.480          37.16            82.28   \n",
       "560           ...                   15.300          33.17           100.20   \n",
       "561           ...                   11.920          38.30            75.19   \n",
       "562           ...                   17.520          42.79           128.70   \n",
       "563           ...                   24.290          29.41           179.10   \n",
       "564           ...                   25.450          26.40           166.10   \n",
       "565           ...                   23.690          38.25           155.00   \n",
       "566           ...                   18.980          34.12           126.70   \n",
       "567           ...                   25.740          39.42           184.60   \n",
       "568           ...                    9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560          0.71190   \n",
       "1        1956.0           0.12380            0.18660          0.24160   \n",
       "2        1709.0           0.14440            0.42450          0.45040   \n",
       "3         567.7           0.20980            0.86630          0.68690   \n",
       "4        1575.0           0.13740            0.20500          0.40000   \n",
       "5         741.6           0.17910            0.52490          0.53550   \n",
       "6        1606.0           0.14420            0.25760          0.37840   \n",
       "7         897.0           0.16540            0.36820          0.26780   \n",
       "8         739.3           0.17030            0.54010          0.53900   \n",
       "9         711.4           0.18530            1.05800          1.10500   \n",
       "10       1150.0           0.11810            0.15510          0.14590   \n",
       "11       1299.0           0.13960            0.56090          0.39650   \n",
       "12       1332.0           0.10370            0.39030          0.36390   \n",
       "13        876.5           0.11310            0.19240          0.23220   \n",
       "14        697.7           0.16510            0.77250          0.69430   \n",
       "15        943.2           0.16780            0.65770          0.70260   \n",
       "16       1138.0           0.14640            0.18710          0.29140   \n",
       "17       1315.0           0.17890            0.42330          0.47840   \n",
       "18       2398.0           0.15120            0.31500          0.53720   \n",
       "19        711.2           0.14400            0.17730          0.23900   \n",
       "20        630.5           0.13120            0.27760          0.18900   \n",
       "21        314.9           0.13240            0.11480          0.08867   \n",
       "22        980.9           0.13900            0.59540          0.63050   \n",
       "23       2615.0           0.14010            0.26000          0.31550   \n",
       "24       2215.0           0.18050            0.35780          0.46950   \n",
       "25       1461.0           0.15450            0.39490          0.38530   \n",
       "26        896.9           0.15250            0.66430          0.55390   \n",
       "27       1403.0           0.13380            0.21170          0.34460   \n",
       "28       1269.0           0.16410            0.61100          0.63350   \n",
       "29       1227.0           0.12550            0.28120          0.24890   \n",
       "..          ...               ...                ...              ...   \n",
       "539       223.6           0.15960            0.30640          0.33930   \n",
       "540       457.8           0.13450            0.21180          0.17970   \n",
       "541       808.9           0.13400            0.42020          0.40400   \n",
       "542       826.4           0.10600            0.13760          0.16110   \n",
       "543       629.6           0.10720            0.13810          0.10620   \n",
       "544       688.6           0.12640            0.20370          0.13770   \n",
       "545       729.8           0.12160            0.15170          0.10490   \n",
       "546       384.9           0.12850            0.08842          0.04384   \n",
       "547       357.4           0.14610            0.22460          0.17830   \n",
       "548       364.2           0.11990            0.09546          0.09350   \n",
       "549       505.6           0.12040            0.16330          0.06194   \n",
       "550       412.3           0.10010            0.07348          0.00000   \n",
       "551       436.6           0.10870            0.17820          0.15640   \n",
       "552       594.7           0.12340            0.10640          0.08653   \n",
       "553       295.8           0.11030            0.08298          0.07993   \n",
       "554       595.7           0.12270            0.16200          0.24390   \n",
       "555       357.6           0.13840            0.17100          0.20000   \n",
       "556       347.3           0.12650            0.12000          0.01005   \n",
       "557       330.6           0.10730            0.07158          0.00000   \n",
       "558       733.5           0.10260            0.31710          0.36620   \n",
       "559       474.2           0.12980            0.25170          0.36300   \n",
       "560       706.7           0.12410            0.22640          0.13260   \n",
       "561       439.6           0.09267            0.05494          0.00000   \n",
       "562       915.0           0.14170            0.79170          1.17000   \n",
       "563      1819.0           0.14070            0.41860          0.65990   \n",
       "564      2027.0           0.14100            0.21130          0.41070   \n",
       "565      1731.0           0.11660            0.19220          0.32150   \n",
       "566      1124.0           0.11390            0.30940          0.34030   \n",
       "567      1821.0           0.16500            0.86810          0.93870   \n",
       "568       268.6           0.08996            0.06444          0.00000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                 0.26540          0.4601                  0.11890  \n",
       "1                 0.18600          0.2750                  0.08902  \n",
       "2                 0.24300          0.3613                  0.08758  \n",
       "3                 0.25750          0.6638                  0.17300  \n",
       "4                 0.16250          0.2364                  0.07678  \n",
       "5                 0.17410          0.3985                  0.12440  \n",
       "6                 0.19320          0.3063                  0.08368  \n",
       "7                 0.15560          0.3196                  0.11510  \n",
       "8                 0.20600          0.4378                  0.10720  \n",
       "9                 0.22100          0.4366                  0.20750  \n",
       "10                0.09975          0.2948                  0.08452  \n",
       "11                0.18100          0.3792                  0.10480  \n",
       "12                0.17670          0.3176                  0.10230  \n",
       "13                0.11190          0.2809                  0.06287  \n",
       "14                0.22080          0.3596                  0.14310  \n",
       "15                0.17120          0.4218                  0.13410  \n",
       "16                0.16090          0.3029                  0.08216  \n",
       "17                0.20730          0.3706                  0.11420  \n",
       "18                0.23880          0.2768                  0.07615  \n",
       "19                0.12880          0.2977                  0.07259  \n",
       "20                0.07283          0.3184                  0.08183  \n",
       "21                0.06227          0.2450                  0.07773  \n",
       "22                0.23930          0.4667                  0.09946  \n",
       "23                0.20090          0.2822                  0.07526  \n",
       "24                0.20950          0.3613                  0.09564  \n",
       "25                0.25500          0.4066                  0.10590  \n",
       "26                0.27010          0.4264                  0.12750  \n",
       "27                0.14900          0.2341                  0.07421  \n",
       "28                0.20240          0.4027                  0.09876  \n",
       "29                0.14560          0.2756                  0.07919  \n",
       "..                    ...             ...                      ...  \n",
       "539               0.05000          0.2790                  0.10660  \n",
       "540               0.06918          0.2329                  0.08134  \n",
       "541               0.12050          0.3187                  0.10230  \n",
       "542               0.10950          0.2722                  0.06956  \n",
       "543               0.07958          0.2473                  0.06443  \n",
       "544               0.06845          0.2249                  0.08492  \n",
       "545               0.07174          0.2642                  0.06953  \n",
       "546               0.02381          0.2681                  0.07399  \n",
       "547               0.08333          0.2691                  0.09479  \n",
       "548               0.03846          0.2552                  0.07920  \n",
       "549               0.03264          0.3059                  0.07626  \n",
       "550               0.00000          0.2458                  0.06592  \n",
       "551               0.06413          0.3169                  0.08032  \n",
       "552               0.06498          0.2407                  0.06484  \n",
       "553               0.02564          0.2435                  0.07393  \n",
       "554               0.06493          0.2372                  0.07242  \n",
       "555               0.09127          0.2226                  0.08283  \n",
       "556               0.02232          0.2262                  0.06742  \n",
       "557               0.00000          0.2475                  0.06969  \n",
       "558               0.11050          0.2258                  0.08004  \n",
       "559               0.09653          0.2112                  0.08732  \n",
       "560               0.10480          0.2250                  0.08321  \n",
       "561               0.00000          0.1566                  0.05905  \n",
       "562               0.23560          0.4089                  0.14090  \n",
       "563               0.25420          0.2929                  0.09873  \n",
       "564               0.22160          0.2060                  0.07115  \n",
       "565               0.16280          0.2572                  0.06637  \n",
       "566               0.14180          0.2218                  0.07820  \n",
       "567               0.26500          0.4087                  0.12400  \n",
       "568               0.00000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_clean = df.drop('id',axis=1)\n",
    "y_train = df_clean['diagnosis']\n",
    "X_train = df_clean.drop('diagnosis',axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_value = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "malignant  = pca_value[y_train=='M']\n",
    "benign = pca_value[y_train=='B']\n",
    "plt.scatter(malignant[::,0],malignant[::,1],label=\"Malignant\",color=\"red\",alpha=0.5)\n",
    "plt.scatter(benign[::,0],benign[::,1],label=\"Benign\",color=\"green\",alpha=0.5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets check pca with non-linearity \n",
    "from sklearn.manifold import Isomap\n",
    "isomap = Isomap(n_components=2,n_neighbors=6)\n",
    "pca_value_iso = isomap.fit_transform(X_train)\n",
    "\n",
    "malignant_iso  = pca_value_iso[y_train=='M']\n",
    "benign_iso = pca_value_iso[y_train=='B']\n",
    "plt.scatter(malignant_iso[::,0],malignant_iso[::,1],label=\"Malignant\")\n",
    "plt.scatter(benign_iso[::,0],benign_iso[::,1],label=\"Benign\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-folds of data\n",
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_train,y_train,test_size=0.30)\n",
    "X_train2,X_test2,y_train2,y_test2=train_test_split(X_train,y_train,test_size=0.30)\n",
    "X_train3,X_test3,y_train3,y_test3=train_test_split(X_train,y_train,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('C=',C_value,' gamma=',gamma_value)? (<ipython-input-22-85dab154a328>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-85dab154a328>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    print 'C=',C_value,' gamma=',gamma_value\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('C=',C_value,' gamma=',gamma_value)?\n"
     ]
    }
   ],
   "source": [
    "for gamma_value in [0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]:\n",
    "    for C_value in[0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000,30000]:\n",
    "        clf1 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf2 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf3 = SVC(C = C_value,gamma = gamma_value)\n",
    "\n",
    "        clf1.fit(X_train1,y_train1)\n",
    "        clf2.fit(X_train2,y_train2)\n",
    "        clf3.fit(X_train3,y_train3)\n",
    "\n",
    "        model1_score = clf1.score(X_train1,y_train1)\n",
    "        test1_score = clf1.score(X_test1,y_test1)\n",
    "        model2_score = clf2.score(X_train2,y_train2)\n",
    "        test2_score = clf2.score(X_test2,y_test2)\n",
    "        model3_score = clf3.score(X_train3,y_train3)\n",
    "        test3_score = clf3.score(X_test3,y_test3)\n",
    "\n",
    "        print 'C=',C_value,' gamma=',gamma_value\n",
    "        print 'M1 : ',model1_score,' M2 : ',model2_score,' M3 : ',model3_score ,'M avg',(model1_score+model2_score+model3_score)/3 \n",
    "        print 'T1 : ',test1_score,' T2 : ',test2_score,' T3 : ',test3_score ,'T avg',(test1_score+test2_score+test3_score)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('C=',C_value,' gamma=',gamma_value)? (<ipython-input-23-85dab154a328>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-85dab154a328>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    print 'C=',C_value,' gamma=',gamma_value\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('C=',C_value,' gamma=',gamma_value)?\n"
     ]
    }
   ],
   "source": [
    "for gamma_value in [0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]:\n",
    "    for C_value in[0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000,30000]:\n",
    "        clf1 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf2 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf3 = SVC(C = C_value,gamma = gamma_value)\n",
    "\n",
    "        clf1.fit(X_train1,y_train1)\n",
    "        clf2.fit(X_train2,y_train2)\n",
    "        clf3.fit(X_train3,y_train3)\n",
    "\n",
    "        model1_score = clf1.score(X_train1,y_train1)\n",
    "        test1_score = clf1.score(X_test1,y_test1)\n",
    "        model2_score = clf2.score(X_train2,y_train2)\n",
    "        test2_score = clf2.score(X_test2,y_test2)\n",
    "        model3_score = clf3.score(X_train3,y_train3)\n",
    "        test3_score = clf3.score(X_test3,y_test3)\n",
    "\n",
    "        print 'C=',C_value,' gamma=',gamma_value\n",
    "        print 'M1 : ',model1_score,' M2 : ',model2_score,' M3 : ',model3_score ,'M avg',(model1_score+model2_score+model3_score)/3 \n",
    "        print 'T1 : ',test1_score,' T2 : ',test2_score,' T3 : ',test3_score ,'T avg',(test1_score+test2_score+test3_score)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.01  gamma= 1e-05\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 1e-05\n",
      "M1 :  0.9213836477987422  M2 :  0.9339622641509434  M3 :  0.9150943396226415 M avg 0.9234800838574424\n",
      "T1 :  0.9197080291970803  T2 :  0.8832116788321168  T3 :  0.927007299270073 T avg 0.9099756690997567\n",
      "C= 0.1  gamma= 1e-05\n",
      "M1 :  0.9213836477987422  M2 :  0.9433962264150944  M3 :  0.9150943396226415 M avg 0.9266247379454926\n",
      "T1 :  0.8978102189781022  T2 :  0.8905109489051095  T3 :  0.9416058394160584 T avg 0.9099756690997567\n",
      "C= 0.3  gamma= 1e-05\n",
      "M1 :  0.9245283018867925  M2 :  0.9559748427672956  M3 :  0.9119496855345912 M avg 0.9308176100628932\n",
      "T1 :  0.9197080291970803  T2 :  0.8905109489051095  T3 :  0.9343065693430657 T avg 0.9148418491484186\n",
      "C= 1  gamma= 1e-05\n",
      "M1 :  0.9213836477987422  M2 :  0.9528301886792453  M3 :  0.9150943396226415 M avg 0.9297693920335429\n",
      "T1 :  0.9051094890510949  T2 :  0.8905109489051095  T3 :  0.948905109489051 T avg 0.9148418491484186\n",
      "C= 3  gamma= 1e-05\n",
      "M1 :  0.9276729559748428  M2 :  0.9528301886792453  M3 :  0.9213836477987422 M avg 0.9339622641509434\n",
      "T1 :  0.927007299270073  T2 :  0.8905109489051095  T3 :  0.948905109489051 T avg 0.9221411192214112\n",
      "C= 10  gamma= 1e-05\n",
      "M1 :  0.9433962264150944  M2 :  0.9591194968553459  M3 :  0.949685534591195 M avg 0.950733752620545\n",
      "T1 :  0.927007299270073  T2 :  0.9051094890510949  T3 :  0.948905109489051 T avg 0.927007299270073\n",
      "C= 30  gamma= 1e-05\n",
      "M1 :  0.9559748427672956  M2 :  0.9748427672955975  M3 :  0.9528301886792453 M avg 0.9612159329140462\n",
      "T1 :  0.927007299270073  T2 :  0.9051094890510949  T3 :  0.9416058394160584 T avg 0.9245742092457422\n",
      "C= 100  gamma= 1e-05\n",
      "M1 :  0.9622641509433962  M2 :  0.9874213836477987  M3 :  0.9622641509433962 M avg 0.9706498951781971\n",
      "T1 :  0.9562043795620438  T2 :  0.8978102189781022  T3 :  0.9562043795620438 T avg 0.9367396593673968\n",
      "C= 300  gamma= 1e-05\n",
      "M1 :  0.9716981132075472  M2 :  0.9905660377358491  M3 :  0.9716981132075472 M avg 0.9779874213836478\n",
      "T1 :  0.948905109489051  T2 :  0.8978102189781022  T3 :  0.9562043795620438 T avg 0.9343065693430658\n",
      "C= 1000  gamma= 1e-05\n",
      "M1 :  0.9811320754716981  M2 :  0.9905660377358491  M3 :  0.9811320754716981 M avg 0.9842767295597484\n",
      "T1 :  0.9416058394160584  T2 :  0.8978102189781022  T3 :  0.9562043795620438 T avg 0.9318734793187348\n",
      "C= 3000  gamma= 1e-05\n",
      "M1 :  0.9842767295597484  M2 :  0.9937106918238994  M3 :  0.9842767295597484 M avg 0.9874213836477987\n",
      "T1 :  0.9197080291970803  T2 :  0.8978102189781022  T3 :  0.9416058394160584 T avg 0.9197080291970803\n",
      "C= 10000  gamma= 1e-05\n",
      "M1 :  0.9905660377358491  M2 :  0.9937106918238994  M3 :  0.9874213836477987 M avg 0.9905660377358491\n",
      "T1 :  0.9051094890510949  T2 :  0.8905109489051095  T3 :  0.9416058394160584 T avg 0.9124087591240876\n",
      "C= 30000  gamma= 1e-05\n",
      "M1 :  0.9968553459119497  M2 :  1.0  M3 :  0.9968553459119497 M avg 0.9979035639412999\n",
      "T1 :  0.9051094890510949  T2 :  0.8832116788321168  T3 :  0.9343065693430657 T avg 0.9075425790754258\n",
      "C= 0.01  gamma= 3e-05\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 3e-05\n",
      "M1 :  0.9213836477987422  M2 :  0.9339622641509434  M3 :  0.9150943396226415 M avg 0.9234800838574424\n",
      "T1 :  0.8905109489051095  T2 :  0.8832116788321168  T3 :  0.927007299270073 T avg 0.9002433090024331\n",
      "C= 0.1  gamma= 3e-05\n",
      "M1 :  0.9150943396226415  M2 :  0.9465408805031447  M3 :  0.9182389937106918 M avg 0.9266247379454926\n",
      "T1 :  0.8613138686131386  T2 :  0.8759124087591241  T3 :  0.9416058394160584 T avg 0.8929440389294404\n",
      "C= 0.3  gamma= 3e-05\n",
      "M1 :  0.9245283018867925  M2 :  0.9559748427672956  M3 :  0.9213836477987422 M avg 0.9339622641509434\n",
      "T1 :  0.9124087591240876  T2 :  0.8905109489051095  T3 :  0.9416058394160584 T avg 0.9148418491484186\n",
      "C= 1  gamma= 3e-05\n",
      "M1 :  0.9339622641509434  M2 :  0.9528301886792453  M3 :  0.9308176100628931 M avg 0.939203354297694\n",
      "T1 :  0.927007299270073  T2 :  0.8905109489051095  T3 :  0.948905109489051 T avg 0.9221411192214112\n",
      "C= 3  gamma= 3e-05\n",
      "M1 :  0.940251572327044  M2 :  0.9622641509433962  M3 :  0.9465408805031447 M avg 0.949685534591195\n",
      "T1 :  0.9343065693430657  T2 :  0.8978102189781022  T3 :  0.9562043795620438 T avg 0.929440389294404\n",
      "C= 10  gamma= 3e-05\n",
      "M1 :  0.9591194968553459  M2 :  0.9716981132075472  M3 :  0.9559748427672956 M avg 0.9622641509433962\n",
      "T1 :  0.927007299270073  T2 :  0.9124087591240876  T3 :  0.948905109489051 T avg 0.9294403892944039\n",
      "C= 30  gamma= 3e-05\n",
      "M1 :  0.9716981132075472  M2 :  0.9842767295597484  M3 :  0.9685534591194969 M avg 0.9748427672955975\n",
      "T1 :  0.927007299270073  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.924574209245742\n",
      "C= 100  gamma= 3e-05\n",
      "M1 :  0.9779874213836478  M2 :  0.9905660377358491  M3 :  0.9779874213836478 M avg 0.9821802935010483\n",
      "T1 :  0.9416058394160584  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9294403892944039\n",
      "C= 300  gamma= 3e-05\n",
      "M1 :  0.9874213836477987  M2 :  0.9937106918238994  M3 :  0.9842767295597484 M avg 0.9884696016771488\n",
      "T1 :  0.8905109489051095  T2 :  0.9124087591240876  T3 :  0.9197080291970803 T avg 0.9075425790754258\n",
      "C= 1000  gamma= 3e-05\n",
      "M1 :  0.9905660377358491  M2 :  0.9937106918238994  M3 :  0.9905660377358491 M avg 0.9916142557651991\n",
      "T1 :  0.8978102189781022  T2 :  0.9051094890510949  T3 :  0.9051094890510949 T avg 0.9026763990267641\n",
      "C= 3000  gamma= 3e-05\n",
      "M1 :  1.0  M2 :  1.0  M3 :  0.9937106918238994 M avg 0.9979035639412999\n",
      "T1 :  0.8978102189781022  T2 :  0.8978102189781022  T3 :  0.8978102189781022 T avg 0.8978102189781022\n",
      "C= 10000  gamma= 3e-05\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.9051094890510949  T2 :  0.8905109489051095  T3 :  0.9051094890510949 T avg 0.9002433090024331\n",
      "C= 30000  gamma= 3e-05\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.9051094890510949  T2 :  0.8905109489051095  T3 :  0.9051094890510949 T avg 0.9002433090024331\n",
      "C= 0.01  gamma= 0.0001\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.0001\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.0001\n",
      "M1 :  0.9245283018867925  M2 :  0.940251572327044  M3 :  0.9213836477987422 M avg 0.9287211740041929\n",
      "T1 :  0.8394160583941606  T2 :  0.8832116788321168  T3 :  0.9416058394160584 T avg 0.8880778588807786\n",
      "C= 0.3  gamma= 0.0001\n",
      "M1 :  0.9371069182389937  M2 :  0.9559748427672956  M3 :  0.9465408805031447 M avg 0.9465408805031447\n",
      "T1 :  0.9197080291970803  T2 :  0.8978102189781022  T3 :  0.948905109489051 T avg 0.9221411192214112\n",
      "C= 1  gamma= 0.0001\n",
      "M1 :  0.9528301886792453  M2 :  0.9654088050314465  M3 :  0.9528301886792453 M avg 0.9570230607966458\n",
      "T1 :  0.927007299270073  T2 :  0.9124087591240876  T3 :  0.948905109489051 T avg 0.9294403892944039\n",
      "C= 3  gamma= 0.0001\n",
      "M1 :  0.9528301886792453  M2 :  0.9748427672955975  M3 :  0.9559748427672956 M avg 0.9612159329140461\n",
      "T1 :  0.9416058394160584  T2 :  0.9197080291970803  T3 :  0.9562043795620438 T avg 0.9391727493917275\n",
      "C= 10  gamma= 0.0001\n",
      "M1 :  0.9716981132075472  M2 :  0.9811320754716981  M3 :  0.9716981132075472 M avg 0.9748427672955975\n",
      "T1 :  0.9197080291970803  T2 :  0.8905109489051095  T3 :  0.927007299270073 T avg 0.9124087591240876\n",
      "C= 30  gamma= 0.0001\n",
      "M1 :  0.9811320754716981  M2 :  0.9937106918238994  M3 :  0.9842767295597484 M avg 0.9863731656184487\n",
      "T1 :  0.9051094890510949  T2 :  0.9197080291970803  T3 :  0.927007299270073 T avg 0.9172749391727494\n",
      "C= 100  gamma= 0.0001\n",
      "M1 :  0.9968553459119497  M2 :  0.9937106918238994  M3 :  0.9905660377358491 M avg 0.9937106918238993\n",
      "T1 :  0.9051094890510949  T2 :  0.9051094890510949  T3 :  0.8978102189781022 T avg 0.902676399026764\n",
      "C= 300  gamma= 0.0001\n",
      "M1 :  1.0  M2 :  0.9968553459119497  M3 :  0.9968553459119497 M avg 0.9979035639412999\n",
      "T1 :  0.8905109489051095  T2 :  0.9197080291970803  T3 :  0.9051094890510949 T avg 0.9051094890510948\n",
      "C= 1000  gamma= 0.0001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8905109489051095  T2 :  0.9051094890510949  T3 :  0.9197080291970803 T avg 0.9051094890510948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 3000  gamma= 0.0001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8905109489051095  T2 :  0.9051094890510949  T3 :  0.9197080291970803 T avg 0.9051094890510948\n",
      "C= 10000  gamma= 0.0001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8905109489051095  T2 :  0.9051094890510949  T3 :  0.9197080291970803 T avg 0.9051094890510948\n",
      "C= 30000  gamma= 0.0001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8905109489051095  T2 :  0.9051094890510949  T3 :  0.9197080291970803 T avg 0.9051094890510948\n",
      "C= 0.01  gamma= 0.0003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.0003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.0003\n",
      "M1 :  0.9559748427672956  M2 :  0.9559748427672956  M3 :  0.940251572327044 M avg 0.950733752620545\n",
      "T1 :  0.8978102189781022  T2 :  0.8102189781021898  T3 :  0.8978102189781022 T avg 0.8686131386861313\n",
      "C= 0.3  gamma= 0.0003\n",
      "M1 :  0.949685534591195  M2 :  0.9591194968553459  M3 :  0.9528301886792453 M avg 0.9538784067085954\n",
      "T1 :  0.9124087591240876  T2 :  0.9197080291970803  T3 :  0.948905109489051 T avg 0.927007299270073\n",
      "C= 1  gamma= 0.0003\n",
      "M1 :  0.9528301886792453  M2 :  0.9716981132075472  M3 :  0.9591194968553459 M avg 0.9612159329140462\n",
      "T1 :  0.9124087591240876  T2 :  0.9197080291970803  T3 :  0.948905109489051 T avg 0.927007299270073\n",
      "C= 3  gamma= 0.0003\n",
      "M1 :  0.9779874213836478  M2 :  0.9779874213836478  M3 :  0.9779874213836478 M avg 0.9779874213836478\n",
      "T1 :  0.9197080291970803  T2 :  0.9124087591240876  T3 :  0.927007299270073 T avg 0.9197080291970803\n",
      "C= 10  gamma= 0.0003\n",
      "M1 :  0.9937106918238994  M2 :  0.9937106918238994  M3 :  0.9874213836477987 M avg 0.9916142557651991\n",
      "T1 :  0.8832116788321168  T2 :  0.9197080291970803  T3 :  0.9343065693430657 T avg 0.9124087591240876\n",
      "C= 30  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  0.9937106918238994  M3 :  0.9937106918238994 M avg 0.9958071278825996\n",
      "T1 :  0.8613138686131386  T2 :  0.9124087591240876  T3 :  0.927007299270073 T avg 0.9002433090024331\n",
      "C= 100  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 300  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 1000  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 3000  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 10000  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 30000  gamma= 0.0003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.9124087591240876  T3 :  0.9343065693430657 T avg 0.9002433090024331\n",
      "C= 0.01  gamma= 0.001\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.001\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.001\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.001\n",
      "M1 :  0.9654088050314465  M2 :  0.9811320754716981  M3 :  0.9716981132075472 M avg 0.9727463312368974\n",
      "T1 :  0.8905109489051095  T2 :  0.9051094890510949  T3 :  0.9416058394160584 T avg 0.9124087591240876\n",
      "C= 1  gamma= 0.001\n",
      "M1 :  0.9905660377358491  M2 :  0.9937106918238994  M3 :  0.9779874213836478 M avg 0.9874213836477987\n",
      "T1 :  0.8978102189781022  T2 :  0.8978102189781022  T3 :  0.9343065693430657 T avg 0.9099756690997567\n",
      "C= 3  gamma= 0.001\n",
      "M1 :  1.0  M2 :  0.9968553459119497  M3 :  0.9905660377358491 M avg 0.9958071278825996\n",
      "T1 :  0.8759124087591241  T2 :  0.8905109489051095  T3 :  0.927007299270073 T avg 0.8978102189781022\n",
      "C= 10  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 30  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 100  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 300  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 1000  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 3000  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 10000  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 30000  gamma= 0.001\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8759124087591241  T2 :  0.8832116788321168  T3 :  0.9197080291970803 T avg 0.8929440389294404\n",
      "C= 0.01  gamma= 0.003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.003\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8540145985401459  T2 :  0.8613138686131386  T3 :  0.9124087591240876 T avg 0.875912408759124\n",
      "C= 3  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 10  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 30  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 100  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 300  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 1000  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 3000  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 10000  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 30000  gamma= 0.003\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.8394160583941606  T2 :  0.8540145985401459  T3 :  0.9124087591240876 T avg 0.8686131386861313\n",
      "C= 0.01  gamma= 0.01\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.01\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.01\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.01\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 3  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 10  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 30  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 100  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 300  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 1000  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 3000  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 10000  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 30000  gamma= 0.01\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6788321167883211  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.6545012165450121\n",
      "C= 0.01  gamma= 0.03\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.03\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.03\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.03\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 100  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 300  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1000  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3000  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10000  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30000  gamma= 0.03\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.01  gamma= 0.1\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.1\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.1\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.1\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 100  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 300  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1000  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3000  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10000  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30000  gamma= 0.1\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.01  gamma= 0.3\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.03  gamma= 0.3\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.1  gamma= 0.3\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 0.3  gamma= 0.3\n",
      "M1 :  0.6289308176100629  M2 :  0.6509433962264151  M3 :  0.6446540880503144 M avg 0.6415094339622641\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 100  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 300  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 1000  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 3000  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 10000  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n",
      "C= 30000  gamma= 0.3\n",
      "M1 :  1.0  M2 :  1.0  M3 :  1.0 M avg 1.0\n",
      "T1 :  0.6861313868613139  T2 :  0.635036496350365  T3 :  0.6496350364963503 T avg 0.656934306569343\n"
     ]
    }
   ],
   "source": [
    "for gamma_value in [0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]:\n",
    "    for C_value in[0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000,30000]:\n",
    "        clf1 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf2 = SVC(C = C_value,gamma = gamma_value)\n",
    "        clf3 = SVC(C = C_value,gamma = gamma_value)\n",
    "\n",
    "        clf1.fit(X_train1,y_train1)\n",
    "        clf2.fit(X_train2,y_train2)\n",
    "        clf3.fit(X_train3,y_train3)\n",
    "\n",
    "        model1_score = clf1.score(X_train1,y_train1)\n",
    "        test1_score = clf1.score(X_test1,y_test1)\n",
    "        model2_score = clf2.score(X_train2,y_train2)\n",
    "        test2_score = clf2.score(X_test2,y_test2)\n",
    "        model3_score = clf3.score(X_train3,y_train3)\n",
    "        test3_score = clf3.score(X_test3,y_test3)\n",
    "\n",
    "        print ('C=',C_value,' gamma=',gamma_value)\n",
    "        print ('M1 : ',model1_score,' M2 : ',model2_score,' M3 : ',model3_score ,'M avg',(model1_score+model2_score+model3_score)/3 )\n",
    "        print ('T1 : ',test1_score,' T2 : ',test2_score,' T3 : ',test3_score ,'T avg',(test1_score+test2_score+test3_score)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-6f6b7c3b5686>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-6f6b7c3b5686>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    print 'train score : ',clf.score(X_train,y_train)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# main classifier with best value\n",
    "C_value = 1000\n",
    "gamma_value = 1e-5\n",
    "clf = SVC(C=C_value,gamma=gamma_value)\n",
    "clf.fit(X_train,y_train)\n",
    "print 'train score : ',clf.score(X_train,y_train)\n",
    "print 'test score : ',clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score :  0.978021978021978\n",
      "test score :  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# main classifier with best value\n",
    "C_value = 1000\n",
    "gamma_value = 1e-5\n",
    "clf = SVC(C=C_value,gamma=gamma_value)\n",
    "clf.fit(X_train,y_train)\n",
    "print ('train score : ',clf.score(X_train,y_train))\n",
    "print ('test score : ',clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-604f6526ba8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgamma_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.00003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mC_value\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mclf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'C'"
     ]
    }
   ],
   "source": [
    "for gamma_value in [0.00001,0.00003,0.0001,0.0003,0.001,0.003,0.01,0.03,0.1,0.3]:\n",
    "    for C_value in[0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000,3000,10000,30000]:\n",
    "        clf1 = DecisionTreeClassifier(C = C_value,gamma = gamma_value)\n",
    "        clf2 = DecisionTreeClassifier(C = C_value,gamma = gamma_value)\n",
    "        clf3 = DecisionTreeClassifier(C = C_value,gamma = gamma_value)\n",
    "\n",
    "        clf1.fit(X_train1,y_train1)\n",
    "        clf2.fit(X_train2,y_train2)\n",
    "        clf3.fit(X_train3,y_train3)\n",
    "\n",
    "        model1_score = clf1.score(X_train1,y_train1)\n",
    "        test1_score = clf1.score(X_test1,y_test1)\n",
    "        model2_score = clf2.score(X_train2,y_train2)\n",
    "        test2_score = clf2.score(X_test2,y_test2)\n",
    "        model3_score = clf3.score(X_train3,y_train3)\n",
    "        test3_score = clf3.score(X_test3,y_test3)\n",
    "\n",
    "        print ('C=',C_value,' gamma=',gamma_value)\n",
    "        print ('M1 : ',model1_score,' M2 : ',model2_score,' M3 : ',model3_score ,'M avg',(model1_score+model2_score+model3_score)/3 )\n",
    "        print ('T1 : ',test1_score,' T2 : ',test2_score,' T3 : ',test3_score ,'T avg',(test1_score+test2_score+test3_score)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-folds of data\n",
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_train,y_train,test_size=0.30)\n",
    "X_train2,X_test2,y_train2,y_test2=train_test_split(X_train,y_train,test_size=0.30)\n",
    "X_train3,X_test3,y_train3,y_test3=train_test_split(X_train,y_train,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f2d5916acde4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-262b365b6f28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train1' is not defined"
     ]
    }
   ],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X_train,y_train,test_size=0.30)\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritam datta shuvo\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing,cross_validation,neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?',-99999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['id'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-816393267fdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3694\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3106\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3108\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3138\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3139\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4386\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4387\u001b[1;33m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[0;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4389\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"labels ['id'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(['id'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-ea23f35be039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fractal_dimension_worst'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fractal_dimension_worst'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array(df.drop(['fractal_dimension_worst'],1))\n",
    "Y = np.array(df['fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['fractal_dimension_worst'],1))\n",
    "Y = np.array(df['fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['diagnosis'],1))\n",
    "Y = np.array(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-71c7a716fc39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1=cross_validation.train_test_split(X_train,y_train,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9197080291970803\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train1,y_train1)\n",
    "accuracy = clf.score(X_test1,y_test1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_measures = np.array([21.56,30.62,103.4,403.5,0.1099,0.1126,0.144,0.1474,0.1454,0.05502,1.176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2.156e+01 3.062e+01 1.034e+02 4.035e+02 1.099e-01 1.126e-01 1.440e-01\n 1.474e-01 1.454e-01 5.502e-02 1.176e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-e87762d6c14b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_measures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \"\"\"\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2.156e+01 3.062e+01 1.034e+02 4.035e+02 1.099e-01 1.126e-01 1.440e-01\n 1.474e-01 1.454e-01 5.502e-02 1.176e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_measures = np.array([21.56,30.62,103.4,403.5,0.1099,0.1126,0.144,0.1474,0.1454,0.05502,1.176,0.9849,2.548,48.55,0.004625,0.04844,0.07359,0.01626,0.01989,0.006213,11.92,42.79,179.1,439.6,0.1298,0.05494,1.17,0.09653,0.225,0.07115])\n",
    "example_measures = example_measures.reshape(1,-1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-212a0e9ef863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexample_measures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample_measures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_measures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_measures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 385\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             )\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([21.56,30.62,103.4,403.5,0.1099,0.1126,0.144,0.1474,0.1454,0.05502,1.176,0.9849,2.548,48.55,0.004625,0.04844,0.07359,0.01626,0.01989,0.006213,11.92,42.79,179.1,439.6,0.1298,0.05494,1.17,0.09653,0.225,0.07115])\n",
    "example_measures = example_measures.reshape(len(example_measures),-1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'B']\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[21.56,30.62,103.4,403.5,0.1099,0.1126,0.144,0.1474,0.1454,0.05502,1.176,0.9849,2.548,48.55,0.004625,0.04844,0.07359,0.01626,0.01989,0.006213,11.92,42.79,179.1,439.6,0.1298,0.05494,1.17,0.09653,0.225,0.07115],[21.56,30.62,103.4,403.5,0.1099,0.1126,0.144,0.1474,0.1454,0.05502,1.176,0.9849,2.548,48.55,0.004625,0.04844,0.07359,0.01626,0.01989,0.006213,11.92,42.79,179.1,439.6,0.1298,0.05494,1.17,0.09653,0.2948,0.08368]])\n",
    "example_measures = example_measures.reshape(len(example_measures),-1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
